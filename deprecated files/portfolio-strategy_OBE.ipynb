{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b4ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import difflib\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "days_in_quarter = 63"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b016b947",
   "metadata": {},
   "source": [
    "Same code from beta_values to retrieve the previously compiled data with the ETF holdings per day for each ETF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96fe384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code is very ad-hoc, someone should clean it up---may be necessary to tweek data files to make it cleaner.\n",
    "\n",
    "file_list = ['data\\\\S000006408.csv', 'data\\\\S000006409.csv', 'data\\\\S000006410.csv', 'data\\\\S000006411.csv', 'data\\\\S000006412.csv', 'data\\\\S000006413.csv', 'data\\\\S000006414.csv', 'data\\\\S000006415.csv', 'data\\\\S000006416.csv', 'data\\\\S000051152.csv', 'data\\\\S000062095.csv']\n",
    "file_list = ['data\\\\S000006408.csv', 'data\\\\S000006409.csv', 'data\\\\S000006410.csv', 'data\\\\S000006411.csv', 'data\\\\S000006412.csv', 'data\\\\S000006413.csv', 'data\\\\S000006414.csv', 'data\\\\S000006415.csv', 'data\\\\S000006416.csv', 'data\\\\S000062095.csv']\n",
    "\n",
    "series_to_ticker_mapping = {\n",
    "    'S000006408': 'XLY',\n",
    "    'S000006409': 'XLP',\n",
    "    'S000006410': 'XLE',\n",
    "    'S000006411': 'XLF',\n",
    "    'S000006412': 'XLV',\n",
    "    'S000006413': 'XLI',\n",
    "    'S000006414': 'XLB',\n",
    "    'S000006415': 'XLK',\n",
    "    'S000006416': 'XLU',\n",
    "    'S000051152': 'XLRE',\n",
    "    'S000062095': 'XLC'\n",
    "}\n",
    "\n",
    "start_date = np.datetime64('2019-10-01')\n",
    "end_date = np.datetime64('2024-04-01')\n",
    "\n",
    "holdings_per_day = {}\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_name = file_name.split('\\\\')[-1]\n",
    "    series = file_name.split('.')[0]\n",
    "    ticker = series_to_ticker_mapping[series]\n",
    "    \n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(f'data/{file_name}')\n",
    "    df.index = df['Tickers']\n",
    "    df = df.iloc[:,:3:-1]\n",
    "    \n",
    "    # This is an ad-hoc fix for the fact that some tickers are duplicated because the associated company name\n",
    "    # label is not consistent (e.g. LOW in the ETF XLY)\n",
    "    df = df.groupby(df.index).sum()\n",
    "    \n",
    "    df.columns = pd.to_datetime(df.columns)\n",
    "    \n",
    "    series_holdings_per_day = {}\n",
    "\n",
    "    date_range = np.arange(start_date,end_date)\n",
    "\n",
    "    for date in date_range:\n",
    "        series_holdings_per_day[date] = df[df.columns[df.columns < date].max()]\n",
    "\n",
    "    holdings_per_day[ticker] = pd.DataFrame(series_holdings_per_day).transpose() != 0\n",
    "    \n",
    "    holdings_per_day[ticker] = holdings_per_day[ticker].where(holdings_per_day[ticker] != 0,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747be51b",
   "metadata": {},
   "source": [
    "These functions were in the beta_values file, but have been amended slightly.  (Please replace the old version of this code in beta_values with this new code.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba72ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returns(ticker,start_date=None,end_date=None):\n",
    "    data = yf.Ticker(ticker).history(period='max')\n",
    "    data.index = data.index.tz_localize(None)\n",
    "    returns = (data['Close'] - data['Close'].shift(1)) / data['Close'].shift(1)\n",
    "    if start_date is not None and end_date is not None:\n",
    "        return returns.loc[str(start_date):str(end_date)]\n",
    "    else:\n",
    "        return returns\n",
    "    \n",
    "def log_returns(ticker,start_date=None,end_date=None):\n",
    "    data = yf.Ticker(ticker).history(period='max')\n",
    "    data.index = data.index.tz_localize(None)\n",
    "    log_returns = np.log(data.Close / data.Close.shift(1))\n",
    "    if start_date is not None and end_date is not None:\n",
    "        return log_returns.loc[start_date.astype(str):end_date.astype(str)]\n",
    "    else:\n",
    "        return log_returns\n",
    "\n",
    "def betas(stock, etf, start_date, end_date, L_min=100, halflife=days_in_quarter):\n",
    "    \n",
    "    # L_min specifies how many days the stock must have been listed to calculate the beta coefficient.  \n",
    "    # If the stock is quite newly listed, then the calculated beta value is unstable and not very meaningful \n",
    "    # (and so we will set beta = np.nan).  \n",
    "    \n",
    "    times = np.arange(start_date,end_date)#pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    betas = []\n",
    "    \n",
    "    stock_returns = returns(stock)\n",
    "    etf_returns = returns(etf)\n",
    "    \n",
    "    two_stocks = pd.DataFrame({stock: stock_returns, etf: etf_returns}).dropna()\n",
    "    \n",
    "    for t in times:\n",
    "         \n",
    "        # Include only columns through t-1 so that the beta on day t depends only on returns from before day t:\n",
    "        \n",
    "        etf_t = two_stocks.loc[:(t-1),etf].values.reshape(-1, 1)\n",
    "        stock_t = two_stocks.loc[:(t-1),stock].values\n",
    "\n",
    "        L = len(stock_t)\n",
    "        \n",
    "        alpha = 0.5 ** (1 / halflife)\n",
    "        \n",
    "        # Calculate exponentially decaying weights for linear regression, so that we weight more \n",
    "        # recent returns more heavily.\n",
    "        \n",
    "        weights = alpha ** (L - 1 - np.arange(L))\n",
    "        weights /= weights.sum()\n",
    "        \n",
    "        # Compute regression coefficient beta, which measures how much the stock returns \n",
    "        # are expected to move in response to ETF returns.  Stocks in an ETF with larger betas\n",
    "        # contribute more to the volatility of the ETF.  Intuitively, stocks with smaller beta\n",
    "        # values are likely less related to the themes surrounding most high-volume selloffs of the ETF.\n",
    "              \n",
    "        model = LinearRegression()\n",
    "        \n",
    "        if L > L_min:\n",
    "            model.fit(etf_t, stock_t, sample_weight=weights)\n",
    "            beta = model.coef_[0]\n",
    "        else:\n",
    "            beta = np.nan\n",
    "        \n",
    "        betas.append(beta)\n",
    "    \n",
    "    return pd.Series(data = betas, index = times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e0f12",
   "metadata": {},
   "source": [
    "We now retrieve the previously compiled ETF beta values of the stocks in each ETF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75cb32c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_tickers = {\n",
    "    'XLY',\n",
    "    'XLP',\n",
    "    'XLE',\n",
    "    'XLF',\n",
    "    'XLV',\n",
    "    'XLI',\n",
    "    'XLB',\n",
    "    'XLK',\n",
    "    'XLU',\n",
    "    #'XLRE',\n",
    "    'XLC'\n",
    "}\n",
    "\n",
    "betas_per_day = {}\n",
    "\n",
    "for etf in etf_tickers:\n",
    "    df = pd.read_csv(f\"data/{etf}_betas_per_day.csv\")\n",
    "    df.set_index(df.columns[0],inplace=True)\n",
    "    df.index.name = 'Day'\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    betas_per_day[etf] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94002532",
   "metadata": {},
   "source": [
    "Function to calculate an exponentially weighted z-score for a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd86cf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_weighted_z_score(data,halflife):\n",
    "    return (data - data.ewm(halflife=halflife).mean().shift(1)) / data.ewm(halflife=halflife).std().shift(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e7e4e",
   "metadata": {},
   "source": [
    "For each ETF, our strategy has :\n",
    "\n",
    "(1) *When to invest?*  The idea of our strategy involves investing after a day during which the ETF volume is statistically large and the ETF volume is negative.  We compute these days in `high_volume_neg_return_days` below.\n",
    "\n",
    "(2) *Which stocks to invest in?*\n",
    "\n",
    "Once we choose a day $D$ and a stock $S$ within an ETF, we must determine the following: if we invested in the stock $S$ at the *close* of day $D$ and held it for 40 days, how does the stock's return $r_S$ compare with the return $r_{ETF}$ of the ETF over that same period?  Since we want to measure our portfolio's alpha compared with the ETF, we leverage our portfolio with the ETF beta value $\\beta_S$ of the stock on day $D$.  Therefore, we define the alpha of the stock's 40-day return versus the ETF as $r_S/\\beta_S - r_{ETF}$.  These alphas are computed in `stock_40_day_alpha`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a21cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_log_returns = {}\n",
    "stock_40_day_returns = {}\n",
    "stock_40_day_alpha = {}\n",
    "high_volume_neg_return_days = {}\n",
    "\n",
    "for etf in etf_tickers:      \n",
    "        \n",
    "    # Compile tickers of both the ETF and all stocks in the ETF's holdings from the time period being considered\n",
    "    tickers = []\n",
    "    tickers.append(etf)\n",
    "    stocks = holdings_per_day[etf].columns\n",
    "    tickers.extend(stocks.values.tolist())\n",
    "\n",
    "    # Compute the log returns of each of these tickers during the time period\n",
    "    \n",
    "    etf_stock_log_returns = pd.DataFrame({ticker: log_returns(ticker,start_date=start_date,end_date=end_date) for ticker in tickers})\n",
    "    #etf_stock_log_returns.index = etf_stock_log_returns.index.tz_localize(None)\n",
    "    \n",
    "    # Compute, for each day, the returns from buying the stock AFTER that day and holding for 40 days\n",
    "    \n",
    "    etf_stock_40_day_returns = np.exp(sum(etf_stock_log_returns.shift(-i) for i in range(1,41))) - 1\n",
    "    \n",
    "    # Compute the difference between the stock's 40-day return that we just computed with the corresponding 40-day return of the ETF, leveraging by the stock's ETF beta\n",
    "    \n",
    "    df = etf_stock_40_day_returns[stocks].copy()\n",
    "\n",
    "    for stock in stocks:\n",
    "        df[stock] = (df[stock] - etf_stock_40_day_returns[etf]) / betas_per_day[etf][stock]\n",
    "        \n",
    "    df = df.dropna(how='all')\n",
    "       \n",
    "    etf_stock_40_day_alpha = df\n",
    "    \n",
    "    # Compute the z scores to determine when the ETF volume is statistically large and the ETF return is negative\n",
    "    \n",
    "    start = etf_stock_40_day_alpha.index[0]\n",
    "    end = etf_stock_40_day_alpha.index[-1]\n",
    "    \n",
    "    etf_returns = returns(etf,start_date=start,end_date=end)\n",
    "    \n",
    "    etf_ticker = yf.Ticker(etf)\n",
    "    etf_vol = etf_ticker.history(period='max').Volume.tz_localize(None)    \n",
    "    etf_vol_z_scores = exp_weighted_z_score(etf_vol,halflife=days_in_quarter).loc[start:end]\n",
    "    etf_high_volume_neg_return_days = (etf_vol_z_scores >= 3) * (etf_returns < 0)\n",
    "    \n",
    "    # Add all the information just computed to different dictionaries, indexing that information by the ETF ticker\n",
    "    \n",
    "    stock_log_returns[etf] = etf_stock_log_returns\n",
    "    stock_40_day_returns[etf] = etf_stock_40_day_returns\n",
    "    stock_40_day_alpha[etf] = etf_stock_40_day_alpha\n",
    "    high_volume_neg_return_days[etf] = etf_high_volume_neg_return_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0f128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
